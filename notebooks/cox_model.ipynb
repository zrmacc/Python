{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as sps"
      ],
      "metadata": {
        "id": "G8lZ_E1a2ZbX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generation"
      ],
      "metadata": {
        "id": "TdMecf0_9YWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7k3qEq8mzYDH"
      },
      "outputs": [],
      "source": [
        "class GenData:\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      beta=None, \n",
        "      base_rate=0.25, \n",
        "      cens_prop=0.2, \n",
        "      n_covar=3, \n",
        "      n_obs=100,\n",
        "      tau=10,\n",
        "  ) -> None:\n",
        "    \"\"\"Generative parameters.\n",
        "    \n",
        "    Args:\n",
        "      beta: Log hazard ratios.\n",
        "      base_rate: Exponential distribution base rate.\n",
        "      cens_prop: Expected proportion of observations that are censored.\n",
        "      n_covar: Number of covariates. Replaced by len(beta) if beta is provided.\n",
        "      n_obs: Number of observations.\n",
        "      tau: Truncation time.\n",
        "    \n",
        "    \"\"\"\n",
        "    if beta is None:\n",
        "      beta = np.zeros((n_covar,))\n",
        "      n_covar = len(beta)\n",
        "    assert len(beta) == n_covar, \"Length of beta must match number of covariates.\"\n",
        "    self.beta = beta\n",
        "    self.base_rate = base_rate\n",
        "    self.cens_prop = cens_prop\n",
        "    self.n_covar = n_covar\n",
        "    self.n_obs = n_obs\n",
        "    self.tau = tau\n",
        "  \n",
        "  def get_batch(self) -> Dict[str, np.ndarray]:\n",
        "    \n",
        "    # Generate covariates.\n",
        "    x = np.random.normal(loc=0.0, scale=1.0, size=(self.n_obs, self.n_covar))\n",
        "\n",
        "    # Generate event time.\n",
        "    rate = self.base_rate * np.exp(np.matmul(x, self.beta))\n",
        "    event_time = np.random.exponential(scale=1.0 / rate)\n",
        "\n",
        "    # Generate censoring time.\n",
        "    cens_rate = self.cens_prop / (1 - self.cens_prop) * rate \n",
        "    cens_time = np.random.exponential(scale=1.0 / cens_rate)\n",
        "    \n",
        "    # Censored data. \n",
        "    cens_time[cens_time > self.tau] = self.tau\n",
        "    event_cens = np.stack((event_time, cens_time), axis=1)\n",
        "    time = np.min(event_cens, axis=1)\n",
        "    assert len(time) == self.n_obs\n",
        "    status = np.where(event_time <= cens_time, 1.0, 0.0)\n",
        "    \n",
        "    # Output.\n",
        "    return {\n",
        "        \"beta\": self.beta,\n",
        "        \"cens_time\": cens_time,\n",
        "        \"even_time\": event_time,\n",
        "        \"rate\": rate,\n",
        "        \"status\": status,\n",
        "        \"time\": time,\n",
        "        \"x\": x,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(201)\n",
        "data_generator = GenData()\n",
        "data = data_generator.get_batch()"
      ],
      "metadata": {
        "id": "B5KYSt_a3Qrt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = data.get(\"time\")\n",
        "status = data.get(\"status\")\n",
        "print(time[:5])\n",
        "print(status[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5yWPGlZ4ONL",
        "outputId": "04b01af4-2906-4272-a681-a0f9d2fdaa7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.61086877 1.32996653 0.10600733 0.32355925 3.20244274]\n",
            "[1. 1. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cox model"
      ],
      "metadata": {
        "id": "Bwym44rj9cg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ],
      "metadata": {
        "id": "q0lCUDpp9emk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoxLoss:\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      status: np.ndarray,\n",
        "      time: np.ndarray,\n",
        "      x: np.ndarray\n",
        "  ) -> None:\n",
        "    \"\"\"Cox model data.\n",
        "    \n",
        "    Args:\n",
        "      status: Event status, 1 for observed, 0 for censored.\n",
        "      time: Observation time.\n",
        "      x: (n_obs, n_covar) array of covariates.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Sorting. \n",
        "    df_time = pd.DataFrame({\"time\": time, \"status\": status})\n",
        "    df_x = pd.DataFrame(x)\n",
        "    df = pd.concat([df_time, df_x], axis=1)\n",
        "    df = df.sort_values(by=[\"time\", \"status\"], ascending=[True, False])\n",
        "\n",
        "    # Cache.\n",
        "    self.df = df[[\"time\", \"status\"]]\n",
        "    self.n_obs, self.n_covar = x.shape\n",
        "    self.x = np.array(df.drop(columns=[\"time\", \"status\"]))\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def is_pd(x: np.ndarray) -> bool:\n",
        "    \"\"\"Check that matrix is positive definite.\"\"\"\n",
        "    return np.all(np.linalg.eigvals(x) > 0)\n",
        "  \n",
        "\n",
        "  def log_lik(self, beta: np.ndarray) -> float:\n",
        "    \"\"\"Calculate partial log likelihood.\"\"\"\n",
        "    df = self.df\n",
        "    x = self.x\n",
        "    df[\"risk\"] = np.exp(np.matmul(x, beta))\n",
        "\n",
        "    log_lik = 0.0\n",
        "    for idx in range(self.n_obs):\n",
        "      if df.status[idx] == 0.0:\n",
        "        continue\n",
        "      log_lik += np.log(df.risk[idx]) - np.log(np.sum(df.risk[idx:]))\n",
        "    \n",
        "    return log_lik\n",
        "\n",
        "\n",
        "  def grad(self, beta: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Calculate gradient of the partial log likelihood.\"\"\"\n",
        "    df = self.df\n",
        "    x = self.x\n",
        "    df[\"risk\"] = np.exp(np.matmul(x, beta))\n",
        "\n",
        "    score = np.zeros((self.n_covar, ))\n",
        "    for idx in range(self.n_obs):\n",
        "      if df.status[idx] == 0.0:\n",
        "        continue\n",
        "      score += x[idx, :] - np.average(x[idx:, :], weights=df.risk[idx:], axis=0)\n",
        "    return score\n",
        "\n",
        "\n",
        "  def info(self, beta: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Calculate information matrix of the partial log likelihood.\"\"\"\n",
        "    df = self.df\n",
        "    x = self.x\n",
        "    df[\"risk\"] = np.exp(np.matmul(x, beta))\n",
        "\n",
        "    # Outer product tensor: (n_obs, n_covar, n_covar).\n",
        "    x2 = x[:, np.newaxis, :] * x[:, :, np.newaxis]\n",
        "\n",
        "    info = np.zeros((self.n_covar, self.n_covar))\n",
        "    for idx in range(self.n_obs):\n",
        "      if df.status[idx] == 0.0:\n",
        "        continue\n",
        "      avg = np.average(x[idx:, :], weights=df.risk[idx:], axis=0)\n",
        "      info += np.average(x2[idx:, :, :], weights=df.risk[idx:], axis=0) - \\\n",
        "        np.outer(avg, avg)\n",
        "    return info\n",
        "\n",
        "\n",
        "  def inference(self, beta: np.ndarray, t1e=0.05) -> pd.DataFrame:\n",
        "    \"\"\"Tabulate parameter estimates, confidence intervals, and p-values.\n",
        "\n",
        "    Note:\n",
        "      Confidence intervals for beta are on the log hazard ratio scale.\n",
        "    \n",
        "    Args:\n",
        "      beta: Parameter estimation.\n",
        "      t1e: Type I error (for confidence intervals).\n",
        "    \n",
        "    \"\"\"\n",
        "    info = self.info(beta)\n",
        "    if not CoxLoss.is_pd(info):\n",
        "      print(\"Information matrix is not positive definite.\")\n",
        "    \n",
        "    # Calculate standard errors\n",
        "    inv_info = np.linalg.pinv(info)\n",
        "    inv_info[inv_info < 0] = np.inf\n",
        "    se = np.sqrt(np.diagonal(inv_info))\n",
        "\n",
        "    # Calculate confidence intervals.\n",
        "    z = sps.norm.ppf(1.0 - 0.5 * t1e)\n",
        "    lower = beta - z * se\n",
        "    upper = beta + z * se\n",
        "\n",
        "    # Calculate p-value.\n",
        "    p = 2 * sps.norm.sf(np.abs(beta / se))\n",
        "    return pd.DataFrame({\n",
        "        \"beta\": beta,\n",
        "        \"se\": se,\n",
        "        \"lower\": lower,\n",
        "        \"upper\": upper,\n",
        "        \"p\": p,\n",
        "    })"
      ],
      "metadata": {
        "id": "ALf7fsoi9USO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = np.zeros((3, ))\n",
        "loss_fn = CoxLoss(status=data[\"status\"], time=data[\"time\"], x=data[\"x\"])\n",
        "\n",
        "log_lik = loss_fn.log_lik(beta=beta)\n",
        "print(f\"Partial log likelihood: {log_lik:.3f}\")\n",
        "\n",
        "score = loss_fn.grad(beta=beta)\n",
        "print(\"\\nScore:\\n\", score)\n",
        "\n",
        "info = loss_fn.info(beta=beta)\n",
        "print(\"\\nInformation:\\n\", info)"
      ],
      "metadata": {
        "id": "hQkUHUohJAyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354aa12f-97a8-42c0-8b89-e486d3d5a19d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partial log likelihood: -284.399\n",
            "\n",
            "Score:\n",
            " [  4.05806144  -7.33756249 -15.02580012]\n",
            "\n",
            "Information:\n",
            " [[65.01923434 -2.10372762  8.89499086]\n",
            " [-2.10372762 56.95119146 12.68413163]\n",
            " [ 8.89499086 12.68413163 59.58131175]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimation"
      ],
      "metadata": {
        "id": "RoSd1I53sOob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoxEst:\n",
        "\n",
        "  def __init__(\n",
        "      self, \n",
        "      eps=1e-8, \n",
        "      init_beta=None, \n",
        "      max_iter=10,\n",
        "      verbose=True\n",
        "  ) -> None:\n",
        "    \"\"\"Fitting parameters.\n",
        "    \n",
        "    Args:\n",
        "      eps: Minimum improvement in log likelihood.\n",
        "      init_beta: Initial beta. \n",
        "      max_iter: Maximum number of iterations. \n",
        "      verbose: Report fitting progress? \n",
        "\n",
        "    \"\"\"\n",
        "    self.eps = eps\n",
        "    self.init_beta = init_beta\n",
        "    self.max_iter = max_iter\n",
        "    self.verbose = verbose\n",
        "  \n",
        "  def fit(self, loss: CoxLoss) -> np.ndarray:\n",
        "    \n",
        "    # Initialize.\n",
        "    beta = self.init_beta\n",
        "    if beta is None:\n",
        "      beta = np.zeros((loss.n_covar, ))\n",
        "    else:\n",
        "      assert len(beta) == loss.n_covar, \"Length of initial beta does not match the number of covariates.\"\n",
        "\n",
        "    # Newton-Raphson.\n",
        "    loglik = loss.log_lik(beta)\n",
        "    if self.verbose:\n",
        "      print(f\"Init loglik: {loglik:.3f}\")\n",
        "\n",
        "    for step in range(self.max_iter):\n",
        "      grad = loss.grad(beta)\n",
        "      info = loss.info(beta)\n",
        "      beta_next = beta + np.linalg.solve(info, grad)\n",
        "\n",
        "      loglik_next = loss.log_lik(beta_next)\n",
        "      delta = loglik_next - loglik\n",
        "      if self.verbose:\n",
        "        print(f\"Next loglik: {loglik_next:.3f}, delta: {delta:.3f}\")\n",
        "      if delta > self.eps:\n",
        "        beta = beta_next\n",
        "        loglik = loglik_next\n",
        "      else:\n",
        "        break\n",
        "    \n",
        "    return beta"
      ],
      "metadata": {
        "id": "ac6f3sp9sPlZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_fn = CoxEst()\n",
        "beta = fit_fn.fit(loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IItkFBcTvpFG",
        "outputId": "3efd1436-1298-4526-dfae-04b5fb497db5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init loglik: -284.399\n",
            "Next loglik: -283.818, delta: 0.581\n",
            "Next loglik: -283.818, delta: 0.000\n",
            "Next loglik: -283.818, delta: 0.000\n",
            "Next loglik: -283.818, delta: -0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "ye3P8lnP3Z0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = loss_fn.inference(beta)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ3ahO0t3bh1",
        "outputId": "0c7fa57d-f04c-47b2-8dc1-10e9cfa96d4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       beta        se     lower     upper         p\n",
            "0  0.091310  0.124382 -0.152474  0.335094  0.462880\n",
            "1 -0.069019  0.131899 -0.327537  0.189498  0.600783\n",
            "2 -0.254278  0.134428 -0.517753  0.009197  0.058551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall example"
      ],
      "metadata": {
        "id": "sBR83aAd7X_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(102)\n",
        "data_generator = GenData(beta=np.zeros((3, )))\n",
        "data = data_generator.get_batch()\n",
        "loss_fn = CoxLoss(status=data[\"status\"], time=data[\"time\"], x=data[\"x\"])\n",
        "fit_fn = CoxEst(verbose=False)\n",
        "beta = fit_fn.fit(loss_fn)\n",
        "results = loss_fn.inference(beta)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxJMkRMG3mKH",
        "outputId": "33dd969d-a897-4507-bf86-b8c97d502c17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       beta        se     lower     upper         p\n",
            "0 -0.106282  0.111093 -0.324020  0.111456  0.338721\n",
            "1 -0.002975  0.118685 -0.235594  0.229644  0.980000\n",
            "2  0.062114  0.118126 -0.169409  0.293637  0.599009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(103)\n",
        "data_generator = GenData(beta=np.ones((3, )))\n",
        "data = data_generator.get_batch()\n",
        "loss_fn = CoxLoss(status=data[\"status\"], time=data[\"time\"], x=data[\"x\"])\n",
        "fit_fn = CoxEst(verbose=False)\n",
        "beta = fit_fn.fit(loss_fn)\n",
        "results = loss_fn.inference(beta)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWIv4Wa68EEP",
        "outputId": "a117de30-5629-4848-a6f6-289fd256c757"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       beta        se     lower     upper             p\n",
            "0  0.737528  0.167481  0.409272  1.065784  1.064399e-05\n",
            "1  0.698765  0.164892  0.375584  1.021947  2.257962e-05\n",
            "2  0.808253  0.161768  0.491194  1.125313  5.841691e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueMF3bRm8UoK"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}